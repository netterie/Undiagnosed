
---
title: "Code for updating p(tid) to p(tid|OD-N, AIDS)"
output:
    html_document:
      number_sections: true
    theme: united
---

# Constructing p(OD-N|tid)
This is where Ian interprets the data on OD-N by time since seroconversion (sero) to construct p(OD-N|tid). 

* He graphs the data on the regular and log+sqrt scales; then he estimates a linear model for sqrt(odn), i.e. _sqodn_, versus log(tid), i.e. _lsero_. Note that he deals with zeroes by adding 50 days to all tid's. 
* Analyzes the residuals and decides that the variances differ below and above log(tid)=4.5. 
* Uses the standard deviation of the residuals for below and above 4.5 to define _stdlow_ and _stdhigh_
* Defines the log-prob of p(OD-N|tid) on the interval (0, 800) days since seroconversion using
    1. The linear model to predict the residual between the true _sqodn_ and the model-estimated _sqodn_ based on _lsero_.
    2. A logged normal distribution to find where that residual lies on a density centered at 0 with standard deviation of _stdlow_ or _stdhigh_, depending on the _lsero_ level. 
* This creates log p(OD-N|tid) because:
    1. Well, a normal distribution is a probability distribution
    2. It is the correct probability distribution because you give the function the tid (_lsero_) and conditional on that, it tells you where the data's _sqodn_ falls relative to the expected _sqodn_. Think of the classic OLS graph of y versus x and the sideways probability distributions.
* Then he graphs the resulting p(OD-N|tid) probability distributions on the _lsero_ range of 0:2000 for various OD-N values. Remember that he caps the range at 0:800 days, since that was the max range of the data, so after day=800, the distribution is flat. 


```{r}
library(ggplot2)
dat <- read.csv("odn-n\ Sero.csv")
names(dat) <- c("sero","odn","a","b")

qplot(pmax(0,sero),odn,data=dat) + geom_smooth()
qplot(log(pmax(0,sero)+50),sqrt(odn),data=dat) + geom_smooth()

## transform to linear relationship
lsero <- log(pmax(0,dat$sero)+50)
sqodn <- sqrt(dat$odn)

## linear model for relationship
mod <- lm(sqodn ~ lsero)
summary(mod)
resid <- mod$residuals
qplot(lsero,abs(resid))

## cut point for variance estimation
## variances differ below and above cut point
lcut <- lsero > 4.5
qplot(resid[lcut])
qplot(resid[!lcut])

stdlow <- sd(resid[!lcut])
stdhigh <- sd(resid[lcut])



## Log probability of an BED od-n given date since sero conversion in days 
logProbOdn <- function(odn, sero){
  sero <- pmin(800, sero) # Don't project out of validated range
  coef <- structure(c(-1.40644598916766, 0.458516848702799), .Names = c("(Intercept)", "lsero"))
  stdlow <- 0.06160604
  stdhigh <- 0.2168296
  lsero <- log(pmax(0, sero)+50)
  sqodn <- sqrt(odn)
  std <- ifelse(lsero < 4.5, stdlow, stdhigh)
  resid <- sqodn - coef[1] - coef[2]*lsero
  dnorm(resid, mean=0, sd=std, log=TRUE)
}


## plots showing test discrimination at od-n = .5, .75, 1, 1.5, 2, 3
plot(exp(logProbOdn(.5, (0:2000))),type='l')
plot(exp(logProbOdn(.75, (0:2000))),type='l')
plot(exp(logProbOdn(1, (0:2000))),type='l')
plot(exp(logProbOdn(1.5, (0:2000))),type='l')
plot(exp(logProbOdn(2, (0:2000))),type='l')
plot(exp(logProbOdn(3, (0:2000))),type='l')
```

# Constructing p(AIDS|tid)
This is where Ian interprets Lui-based weibull to construct p(AIDS|tid). AIDS is dichotomous, so there is just AIDS=TRUE and AIDS=FALSE.

* Defines the log-likelihood using the weibulls
    1. There's a subtlety where the density is used for AIDS=TRUE but the cumulative density for AIDS=FALSE, even though that should be a probability distribution too, not a cdf. Is that because the weibull actually describes the conditional pdf, e.g. conditional on not progressing to AIDS before t=sero, p(sero)? 
    2. Unlike the BED, there is no normal distribution for each level of tid/sero. But I still don't understand why p(AIDS=TRUE|tid=T) + p(AIDS=FALSE|tid=T) doesnt = 1. That's a question. 
    3. **I'm pretty sure he is doing p(tid|AIDS), not p(AIDS|tid).**
* Graphs over 20 years for AIDS=FALSE and AIDS=TRUE. Remember these are probabilities, not cumulative probabilities
    1. Probability of NO concurrent diagnosis decreases monotonically with increasing tid
    2. Probability of concurrent diagnosis is normal-ish peaking around 10 years

```{r}
## log probability of having AIDS at time of diagnosis based on wiebull
## Assumes individuals become diagnosed once they progress to AIDS
## 
## If subject has aids at dx, the probability that they have progressed is
## dweibull(time, 2.5, 1/0.086)
## 
## If the subject does not have aids, then the probability that they
## have not progressed at any time prior to the current time is
## 1- pweibull(time, 2.5, 1/0.086)
logProbAids <- function(aids, sero){
  if(length(aids) == 1)
    aids <- rep(aids, length(sero))
  sero <- pmax(0, sero) / 365
  sh <- 2.5
  sc <- 1/0.086
  ifelse(aids, dweibull(sero,shape = sh,scale = sc, log=TRUE),
         pweibull(sero,shape = sh,scale = sc, log.p=TRUE, lower.tail = FALSE))
}

## 20 year discrimination if aids=FALSE
plot(exp(logProbAids(FALSE, (0:(365*20)))),type='l')
## 20 year discrimination if aids=TRUE
plot(exp(logProbAids(TRUE, (0:(365*20)))),type='l')
```


# Putting it all together to get p(tid|OD-N, AIDS)
The _naiveBayes_ function gives the full probability distribution. How?

* Defines _times_ in days from 0 to 20 years
* Defines a _logProb_ offset
    1. Initially as zero for each _times_
    2. Updated to -Inf for _times_ greater than the input tid
* This works as log(p(tid)) because 
    1. The BC has constant probability over 0 to x~i~, and 0 probability after outside the window. Since we will scale the probability distribution at the end, the actual value of the constant, log(1/x~i~) doesn't matter?
    2. Keeps probability at 0 beyond the window x~i~
* Adds _logProbAids_ and _logProbOdn_ to _logProb_ to get the updated log-likelihood
* Creates a probability distribution by 
    1. Exponentiating _logProb_ - max(_logProb_). Why center around max? Because that's the maximum likelihood estimate, so everything should be relative to that peak? I think this just looks funny to me because I'm used to the maximum likelihood estimate being generated through an optimization. But here, we have completely specified log probs, rather than ones with unknown parameters that have to be estimated. 
    2. Scale
    
Then he's got different graphs of p(tid|OD-N, AIDS) and finally, p(TID) for a distribution of OD-N and AIDS. The p(tid|...) graphs aren't very interesting because they all go out to 20 years, rather than having the max be x~i~. But I get the idea.

```{r}

## Computes the p(tid | odn, aids) using naive bayes
naiveBayes <- function(odn, aids, lastNegHIV){
  times <- 0:(365*20)
  nt <- length(times)
  logProb <- rep(0,nt)
  
  logProb[times > lastNegHIV] <- -Inf
  logProb <- logProb + logProbAids(aids, times)
  logProb <- logProb + logProbOdn(odn, times)
  prob <- exp(logProb - max(logProb))
  prob <- prob / sum(prob)
  prob
}

## #Probability distributions for different cases

## non-aids, never tested, lowish odn. Note the hgher concentration toward
## recent infection
plot(naiveBayes(odn=1.5, aids=FALSE, lastNegHIV=365*20),type='l')

## last negative 2 years ago, comes in with aids and high odn. note the high concentration
## toward the end of the 2 year interval
plot(naiveBayes(odn=3, aids=TRUE, lastNegHIV=365*2),type='l')


## very small odn, but with aids and never tested. Possible misclassification of aids
## due to primary infection. note the high concentration on recent dates
plot(naiveBayes(odn=.25, aids=TRUE, lastNegHIV=365*20),type='l')


## #Calculation of TID distribution across a sample
tidDat <- data.frame(odn=c(1.5,2,.25, 2, 1, 3, 1), aids=c(F,T,T,F, F, F, F), ln=365*c(20,2,20,4, 10, 8, 1))
individDists <- apply(tidDat, 1, function(x) naiveBayes(x[1],x[2],x[3]))
tid <- rowMeans(individDists)
plot(tid,type='l')
```

# Conclusion

I'm about 75% confident that I could duplicate this structure to replicate the simple analysis for DOH. But that's how I would want to proceed - do the simple analysis, and then work on replication using this structure. I can follow Ian's work but I don't have enough stats savvy to ensure that I would do everything right starting from my own blank slate. 

Also, he's basically given me the structure for incorporating the AIDS TID, so that falls nicely into what we said we'd do for Matt.

I think it's a really good code base/option to have available to us, for when anyone has an idea of informing p(tid) beyond the Base Case. 

Moreover, remember the importance of accounting for variation in SPVL and how I argued for a population-level approach to incorporating CD4? Ian's use of the mixed-effects model and finding positive slopes for CD4 is a good reason why our distilled approach is actually more reasonable.









